{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e38a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72fb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"mnist_train.csv\")\n",
    "test = pd.read_csv(\"mnist_test.csv\")\n",
    "\n",
    "training = []\n",
    "training_labels = []\n",
    "validation = []\n",
    "validation_labels = []\n",
    "testing = []\n",
    "testing_labels = []\n",
    "\n",
    "def stacker(df):\n",
    "    image_list = [torch.tensor(df.iloc[img].values) for img in range(len(df))]\n",
    "    stacked = torch.stack(image_list).float()/255\n",
    "    return stacked\n",
    "def loader(data, labels):\n",
    "    zipped_data = list(zip(torch.cat(data).view(-1, 28*28),tensor(labels).unsqueeze(1)))\n",
    "    return DataLoader(zipped_data, batch_size=256, shuffle=True)\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    test_images = test[test[\"label\"] == i].iloc[:, 1:785]\n",
    "    images = train[train[\"label\"] == i].iloc[:, 1:785]\n",
    "    \n",
    "    validation_images = images.iloc[0:(round(len(images)*.2)+1),].reset_index().drop(labels =\"index\", axis=1)\n",
    "    train_images = images.iloc[(len(validation_images)+1):,].reset_index().drop(labels =\"index\", axis=1)\n",
    "    \n",
    "    test_stacked = stacker(test_images)\n",
    "    testing_labels.extend([i]*len(test_stacked))\n",
    "    testing.append(test_stacked)\n",
    "    \n",
    "    valid_stacked = stacker(validation_images)\n",
    "    validation_labels.extend([i]*len(valid_stacked))\n",
    "    validation.append(valid_stacked)\n",
    "    \n",
    "    train_stacked = stacker(train_images)\n",
    "    training_labels.extend([i]*len(train_stacked))\n",
    "    training.append(train_stacked)\n",
    "\n",
    "\n",
    "testing_data = loader(testing, testing_labels)\n",
    "validation_data = loader(validation, validation_labels)\n",
    "training_data = loader(training, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f1adb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size1,output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "def mnist_loss(prds,trgt):\n",
    "        prds = prds.sigmoid()\n",
    "        return torch.where(trgt==1, 1-prds, prds).mean()\n",
    "\n",
    "def validate_epoch(model, valid_dl):\n",
    "        accs = [batch_accuracy(model(x),y) for x,y in valid_dl]\n",
    "        return round(torch.stack(accs).mean().item(), 4)\n",
    "    \n",
    "def batch_accuracy(x, y):\n",
    "        preds = softmax(x)\n",
    "        predicted_value = torch.argmax(preds, dim=1)\n",
    "        trgts = y.flatten()\n",
    "        bools = predicted_value == trgts\n",
    "        acc = bools.to(torch.float).mean()\n",
    "        return acc\n",
    "\n",
    "def softmax(preds):\n",
    "    preds = preds-torch.max(preds)\n",
    "    return torch.exp(preds)/torch.sum(torch.exp(preds), dim=1).unsqueeze(1)\n",
    "\n",
    "\n",
    "def cross_entropy_loss(preds, trgt):\n",
    "        \n",
    "        soft = softmax(preds)\n",
    "        one_hot = torch.zeros(trgt.shape[0], soft.shape[1])\n",
    "        \n",
    "        for i in range(one_hot.size(0)):\n",
    "            index = trgt[i, 0].item()\n",
    "            one_hot[i, int(index)] = 1\n",
    "        \n",
    "        loss = -torch.sum(torch.log(soft)*one_hot)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f80e8be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "lr = 0.0001\n",
    "model = SimpleNN(28*28, 30, 10)\n",
    "\n",
    "opt = SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "94e80579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.674091100692749 \n",
      " model accuracy: 96%\n",
      "model accuracy: 96%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "for i in range(epochs):\n",
    "    for x,y in training_data:\n",
    "        preds = model(x)\n",
    "        loss = cross_entropy_loss(preds, y)\n",
    "        loss.backward()\n",
    "        for param in model.parameters():\n",
    "            param.data -= lr*param.grad.data\n",
    "            param.grad = None\n",
    "    if loss < 1.5:\n",
    "        break\n",
    "    acc = torch.stack([batch_accuracy(softmax(model(x)), y) for x,y in validation_data]).mean()\n",
    "    clear_output(wait=True)  \n",
    "    print(f\"Loss: {loss} \\n model accuracy: {acc*100:.0f}%\")\n",
    "    time.sleep(.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4108c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
